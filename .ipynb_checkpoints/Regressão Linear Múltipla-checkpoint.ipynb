{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad35ff0a",
   "metadata": {},
   "source": [
    "# Regressão Linear Múltipla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa17350",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "1. CRIM: per capita crime rate by town\n",
    "2. ZN: proportion of residential land zoned for lots over 25,00 sq.ft.\n",
    "3. INDUS: proportion of non-retail business acres pertown\n",
    "4. CHAS: Charles River dummy variable (=1 if track bounds river; 0 otherwise)\n",
    "5. NOX: nitric oxides concentration (parts per 10 million)\n",
    "6. RM: average number of rooms per dwelling\n",
    "7. AGE: proportion of owner-occupied units built prior to 1940\n",
    "8. DIS: weighted distances to five Boston employment centres\n",
    "9. RAD: index of accessibility to radial highways\n",
    "10. TAX: full-value property-tax rate per 10,000\n",
    "11. PTRATIO: pupil-teacher ration by town\n",
    "12. B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT: % lower status of the population\n",
    "14. TARGET: Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bdfb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846860b4",
   "metadata": {},
   "source": [
    "## Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb206f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'TARGET']\n",
    "dataset = pd.read_csv(\"./data/boston-houses.csv\", names = colunas, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da089b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerabndo número de observações e variáveis\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7137a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletando x e y\n",
    "X = dataset.iloc[:, :-1]\n",
    "y = dataset['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9b4873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54792f68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a57abc",
   "metadata": {},
   "source": [
    "## Usando Múltiplos atributos com o StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0ed7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xc = sm.add_constant(X)\n",
    "modelo_v1 = sm.OLS(y, Xc)\n",
    "modelo_v2 = modelo_v1.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d4133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 19 Jul 2022</td> <th>  Prob (F-statistic):</th> <td>6.72e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:10:47</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>   36.4595</td> <td>    5.103</td> <td>    7.144</td> <td> 0.000</td> <td>   26.432</td> <td>   46.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>    <td>   -0.1080</td> <td>    0.033</td> <td>   -3.287</td> <td> 0.001</td> <td>   -0.173</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>      <td>    0.0464</td> <td>    0.014</td> <td>    3.382</td> <td> 0.001</td> <td>    0.019</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>   <td>    0.0206</td> <td>    0.061</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.100</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>    <td>    2.6867</td> <td>    0.862</td> <td>    3.118</td> <td> 0.002</td> <td>    0.994</td> <td>    4.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>     <td>  -17.7666</td> <td>    3.820</td> <td>   -4.651</td> <td> 0.000</td> <td>  -25.272</td> <td>  -10.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>      <td>    3.8099</td> <td>    0.418</td> <td>    9.116</td> <td> 0.000</td> <td>    2.989</td> <td>    4.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>     <td>    0.0007</td> <td>    0.013</td> <td>    0.052</td> <td> 0.958</td> <td>   -0.025</td> <td>    0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>     <td>   -1.4756</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.867</td> <td>   -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>     <td>    0.3060</td> <td>    0.066</td> <td>    4.613</td> <td> 0.000</td> <td>    0.176</td> <td>    0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>     <td>   -0.0123</td> <td>    0.004</td> <td>   -3.280</td> <td> 0.001</td> <td>   -0.020</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th> <td>   -0.9527</td> <td>    0.131</td> <td>   -7.283</td> <td> 0.000</td> <td>   -1.210</td> <td>   -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>       <td>    0.0093</td> <td>    0.003</td> <td>    3.467</td> <td> 0.001</td> <td>    0.004</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>   <td>   -0.5248</td> <td>    0.051</td> <td>  -10.347</td> <td> 0.000</td> <td>   -0.624</td> <td>   -0.425</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.041</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 783.126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>8.84e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.281</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.51e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Tue, 19 Jul 2022   Prob (F-statistic):          6.72e-135\n",
       "Time:                        15:10:47   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         36.4595      5.103      7.144      0.000      26.432      46.487\n",
       "CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043\n",
       "ZN             0.0464      0.014      3.382      0.001       0.019       0.073\n",
       "INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141\n",
       "CHAS           2.6867      0.862      3.118      0.002       0.994       4.380\n",
       "NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262\n",
       "RM             3.8099      0.418      9.116      0.000       2.989       4.631\n",
       "AGE            0.0007      0.013      0.052      0.958      -0.025       0.027\n",
       "DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084\n",
       "RAD            0.3060      0.066      4.613      0.000       0.176       0.436\n",
       "TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005\n",
       "PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696\n",
       "B              0.0093      0.003      3.467      0.001       0.004       0.015\n",
       "LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425\n",
       "==============================================================================\n",
       "Omnibus:                      178.041   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126\n",
       "Skew:                           1.521   Prob(JB):                    8.84e-171\n",
       "Kurtosis:                       8.281   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_v2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd744d4",
   "metadata": {},
   "source": [
    "### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22893c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
      "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
      "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
      "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
      "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Gerando a matriz\n",
    "X = dataset.iloc[:, :-1]\n",
    "matriz_corr = X.corr()\n",
    "print(matriz_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a254945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um Correlation Plot\n",
    "def visualize_corr_matrix(data, hurdle = 0.0):\n",
    "    R = np.corrcoef(data, rowvar = 0)\n",
    "    R[np.where(np.abs(R) < hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap = mpl.cm.coolwarm, alpha = 0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor = False)\n",
    "    heatmap.axes.set_xticklabels(variables, minor = False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(variables, minor = False)\n",
    "    plt.tick_params(axis = 'both', which = 'both', bottom = 'off', top = 'off', left = 'off', right = 'off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "366d87e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando o Plot\n",
    "visualize_corr_matrix(X, hurdle = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b6461",
   "metadata": {},
   "source": [
    "## Avaliando a Multicolinearidade\n",
    "\n",
    "## Autovalores (Eigenvalues) e Autovetores (Eigenvectors)\n",
    "\n",
    "Uma forma ainda mais automática de detectar associações multicolineares (e descobrir problemas numéricos em uma inversão da matriz) é usar autovetores. Em termos simples, os autovetores são uma maneira muito inteligente de recombinar a variância entre as variáveis, criando novos recursos acumulando toda a variância compartilhada. Tal recombinação pode ser obtida usando a função NumPy linalg.eig, resultando em um vetor de autovalores (representando a quantidade de variância recombinada para cada nova variável) e autovetores (uma matriz nos dizendo como as novas variáveis se relacionam com as antigas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0643c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando eigenvalues e eigenvectors\n",
    "corr = np.corrcoef(X, rowvar = 0)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60f5e05",
   "metadata": {},
   "source": [
    "Depois de extrair os autovalores, imprimiros em ordem decrescente e procuramos qualquer elemento cujo valor seja próximo de zer ou pequeno em comparação aos outros. Valores próximos a zero podem representar um problema real para equações normais e outros métodos de otimização baseados na inversão matricial. Valores pequenos representam uma fonte elevada, mas não crítica, de multicolinearidade. Se você detectar qualquer um desses valores baixos, anote a posição no vetor (lembre que a indexação em Python começa com 0).\n",
    "\n",
    "O menor valor está na posição 8. Valor buscar a posição 8 no autovetor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6625eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.12684883 1.43327512 1.24261667 0.85757511 0.83481594 0.65740718\n",
      " 0.53535609 0.39609731 0.06350926 0.27694333 0.16930298 0.18601437\n",
      " 0.22023782]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50792b6",
   "metadata": {},
   "source": [
    "Usando a posição do índice na lista de autovalores, podemos encontrar o vetor específico nos autovetores que contém as variáveis carregadas, ou seja, o nível de associação com os valores originais. No eigenvector, observamos valores nas posições de índice 2, 8 e 9, que estão realmente em destaque em termos de valor absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f465551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0459523   0.08091897  0.25107654 -0.03592171 -0.04363045 -0.0455671\n",
      "  0.03855068  0.01829854  0.63348972 -0.72023345 -0.02339805  0.00446307\n",
      " -0.02443168]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvectors[:,8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c073784",
   "metadata": {},
   "source": [
    "Agora nós imprimimos os nomes das variáveis para saber quais contribuem mais com seus valores para construir o autovetor. Associamos o vetor de variáveis com o eigenvector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93e12cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDUS RAD TAX\n"
     ]
    }
   ],
   "source": [
    "print(variables[2], variables[8], variables[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9cc3ae",
   "metadata": {},
   "source": [
    "Tendo encontrado os culpados da multicolinearidade, o que devemos fazer com essas variáveis? A remoção de algumas delas é geralmente a melhor solução."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7460c",
   "metadata": {},
   "source": [
    "## Gradiente Descendente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "362ef771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os dados\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dadb49",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Podemos aplicar Feature Scalling através de padronização ou normalização. Normalização aplica escala aos dados com intervalos entre 0 e 1. A padronização divide a média pelo desvio padrão para obter uma unidade de variância. Vamos usar a padronização (StandardScaler) pois nesse caso esta técnica ajusta os coeficientes e torna a superfície de erros mais \"tratável\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed0bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a padronização\n",
    "standardization = StandardScaler()\n",
    "Xst = standardization.fit_transform(X)\n",
    "original_means = standardization.mean_\n",
    "original_stds = standardization.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940bca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando X e Y\n",
    "Xst = np.column_stack((Xst, np.ones(observations)))\n",
    "y = dataset['TARGET'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ca3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_w(p):\n",
    "    return np.array([np.random.normal() for j in range(p)])\n",
    "\n",
    "def hypothesis(X,w):\n",
    "    return np.dot(X,w)\n",
    "\n",
    "def loss(X,w,y):\n",
    "    return hypothesis(X,w) - y\n",
    "\n",
    "def squared_loss(X,w,y):\n",
    "    return loss(X,w,y)**2\n",
    "\n",
    "def gradient(X,w,y):\n",
    "    gradients = list()\n",
    "    n = float(len( y ))\n",
    "    for j in range(len(w)):\n",
    "        gradients.append(np.sum(loss(X,w,y) * X[:,j]) / n)\n",
    "    return gradients\n",
    "\n",
    "def update(X,w,y, alpha = 0.01):\n",
    "    return [t - alpha*g for t, g in zip(w, gradient(X,w,y))]\n",
    "\n",
    "def optimize(X,y, alpha = 0.01, eta = 10**-12, iterations = 1000):\n",
    "    w = random_w(X.shape[1])\n",
    "    path = list()\n",
    "    for k in range(iterations):\n",
    "        SSL = np.sum(squared_loss(X,w,y))\n",
    "        new_w = update(X,w,y, alpha = alpha)\n",
    "        new_SSL = np.sum(squared_loss(X,new_w,y))\n",
    "        w = new_w\n",
    "        if k>=5 and (new_SSL - SSL <= eta and new_SSL - SSL >= -eta):\n",
    "            path.append(new_SSL)\n",
    "            return w, path\n",
    "        if k % (iterations / 20) == 0:\n",
    "            path.append(new_SSL)\n",
    "    return w, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50b265a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes finais padronizados: -0.9281, 1.0816, 0.1409, 0.6817, -2.0567, 2.6742, 0.0195, -3.1040, 2.6622, -2.0768, -2.0606, 0.8493, -3.7436, 22.5328\n"
     ]
    }
   ],
   "source": [
    "# IMprimindo o resultado \n",
    "alpha = 0.01\n",
    "w, path = optimize(Xst, y, alpha, eta = 10**-12, iterations = 20000)\n",
    "print(\"Coeficientes finais padronizados: \" + \", \".join(map(lambda x: \"%0.4f\" % x, w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c8d886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desfazendo a padronização\n",
    "unstandardized_betas = w[:-1] / original_stds\n",
    "unstandardized_bias = w[-1]-np.sum((original_means / original_stds) * w[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03107396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bias:  36.4595\n",
      "    CRIM:  -0.1080\n",
      "      ZN:   0.0464\n",
      "   INDUS:   0.0206\n",
      "    CHAS:   2.6867\n",
      "     NOX: -17.7666\n",
      "      RM:   3.8099\n",
      "     AGE:   0.0007\n",
      "     DIS:  -1.4756\n",
      "     RAD:   0.3060\n",
      "     TAX:  -0.0123\n",
      " PTRATIO:  -0.9527\n",
      "       B:   0.0093\n",
      "   LSTAT:  -0.5248\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o resultado\n",
    "print('%8s: %8.4f' % ('bias', unstandardized_bias))\n",
    "for beta, varname in zip(unstandardized_betas, variables):\n",
    "    print('%8s: %8.4f' % (varname, beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ddbee3",
   "metadata": {},
   "source": [
    "## Importância dos Atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aec7e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um modelo\n",
    "modelo = linear_model.LinearRegression(fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139aa5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.767 NOX\n",
      " 3.810 RM\n",
      " 2.687 CHAS\n",
      " 1.476 DIS\n",
      " 0.953 PTRATIO\n",
      " 0.525 LSTAT\n",
      " 0.306 RAD\n",
      " 0.108 CRIM\n",
      " 0.046 ZN\n",
      " 0.021 INDUS\n",
      " 0.012 TAX\n",
      " 0.009 B\n",
      " 0.001 AGE\n"
     ]
    }
   ],
   "source": [
    "modelo.fit(X, y)\n",
    "for coef, var in sorted(zip(map(abs, modelo.coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print(\"%6.3f %s\" % (coef, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3766f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardization = StandardScaler()\n",
    "Stand_coef_linear_reg = make_pipeline(standardization, modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7511ec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3.744 LSTAT\n",
      " 3.104 DIS\n",
      " 2.674 RM\n",
      " 2.662 RAD\n",
      " 2.077 TAX\n",
      " 2.061 PTRATIO\n",
      " 2.057 NOX\n",
      " 1.082 ZN\n",
      " 0.928 CRIM\n",
      " 0.849 B\n",
      " 0.682 CHAS\n",
      " 0.141 INDUS\n",
      " 0.019 AGE\n"
     ]
    }
   ],
   "source": [
    "Stand_coef_linear_reg.fit(X,y)\n",
    "for coef, var in sorted(zip(map(abs, Stand_coef_linear_reg.steps[1][1].coef_), dataset.columns[:-1]), reverse = True):\n",
    "    print(\"%6.3f %s\" % (coef, var))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefafecb",
   "metadata": {},
   "source": [
    "## Usando o R Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af979b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = linear_model.LinearRegression(fit_intercept = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4d31ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_est(X, y):\n",
    "    return r2_score(y, modelo.fit(X,y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7868a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R2: 0.741\n"
     ]
    }
   ],
   "source": [
    "print('Baseline R2: %0.3f' % r2_est(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7de20631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.056 LSTAT\n",
      " 0.044 RM\n",
      " 0.029 DIS\n",
      " 0.028 PTRATIO\n",
      " 0.011 NOX\n",
      " 0.011 RAD\n",
      " 0.006 B\n",
      " 0.006 ZN\n",
      " 0.006 CRIM\n",
      " 0.006 TAX\n",
      " 0.005 CHAS\n",
      " 0.000 INDUS\n",
      " 0.000 AGE\n"
     ]
    }
   ],
   "source": [
    "# Gera o impacto de cada atributo no R2\n",
    "r2_impact = list()\n",
    "for j in range(X.shape[1]):\n",
    "    selection = [i for i in range(X.shape[1]) if i!=j]\n",
    "    r2_impact.append(((r2_est(X,y) - r2_est(X.values[:,selection],y)), dataset.columns[j]))\n",
    "    \n",
    "for imp, varname in sorted(r2_impact, reverse = True):\n",
    "    print('%6.3f %s' % (imp, varname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
